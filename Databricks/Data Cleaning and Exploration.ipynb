{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55506eb3-955b-4606-824f-42727050b538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Listing secret scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "769b6ee7-0035-45ef-adb5-dcbb0bbfd619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.secrets.listScopes())\n",
    "display(dbutils.secrets.list('databricks-secret-scope'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70282359-e6d7-41b0-a78f-97d71b6154a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Connecting to ADLS using service principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61abfabe-a545-466d-8711-fbaf5915c736",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "service_credential = dbutils.secrets.get(scope=\"databricks-secret-scope\",key=\"databricks-crdp-service-principle-secret\")\n",
    "\n",
    "storage_account = \"crdpadlsdev\"\n",
    "application_id = \"fe2198ac-ae05-4b49-96ea-f8ffd5a12c01\"\n",
    "directory_id = \"18ea6cf2-8572-415d-9063-f620b0105a11\"\n",
    "\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", application_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", service_credential)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{directory_id}/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9c43a9b-5093-4e41-8bb2-f87d88e7b503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Listing files in the bronze container of crdpadlsdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6391fb3d-f91c-49db-a9cf-3260d8776198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(dbutils.fs.ls(\"abfss://bronze@crdpadlsdev.dfs.core.windows.net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e092fe35-0861-4c9f-b212-436e063410c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Ingest Data from ADLS (Bronze Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fb88a00-351b-45ed-a699-cf357d485ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"abfss://bronze@crdpadlsdev.dfs.core.windows.net/\"\n",
    " \n",
    "#  Read each CSV file\n",
    "df_description = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"HomeCredit_columns_description.csv\")\n",
    "\n",
    "df_pos_cash = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"POS_CASH_balance.csv\")\n",
    "\n",
    "df_application_train = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"application_train.csv\")\n",
    "\n",
    "df_bureau_balance = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"bureau_balance.csv\")\n",
    "\n",
    "df_credit_card_balance = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"credit_card_balance.csv\")\n",
    "\n",
    "df_installments_payments = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"installments_payments.csv\")\n",
    "\n",
    "df_previous_application = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(base_path + \"previous_application.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c34772-0a51-4f07-a03c-6fdb06d428d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Ingest Data from Azure SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89582660-5e0e-447d-a764-56945e0e0c68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymssql\n",
    "\n",
    "def get_sql_connection(server, database, username, password):\n",
    "    conn = pymssql.connect(\n",
    "        server=server,\n",
    "        user=username,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def read_table_to_pandas(conn, table_name):\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    return pd.read_sql(query, conn)\n",
    "\n",
    "def pandas_to_spark(spark, pandas_df):\n",
    "    return spark.createDataFrame(pandas_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27266298-aaf5-471b-9e8f-51f4f8a964d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connection details\n",
    "server = ''\n",
    "database = ''\n",
    "username = ''\n",
    "password = ''\n",
    "\n",
    "# Connect to Azure SQL\n",
    "conn = get_sql_connection(server, database, username, password)\n",
    "\n",
    "# Load table as pandas\n",
    "pdf = read_table_to_pandas(conn, 'bureau')\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "df_bureau = pandas_to_spark(spark, pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e4baab4-dc28-4c41-a288-e518df2a006c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Profiling & Schema Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ad819c-2a13-411c-ae4b-12fe6ddbc8e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, count\n",
    "\n",
    "def profile_dataframe(df, df_name, num_rows=5):\n",
    "    print(f\"\\n Profiling: {df_name} -->\")\n",
    "    print(\"\\n Schema:\")\n",
    "    df.printSchema()\n",
    "\n",
    "    print(\"\\n Top Rows:\")\n",
    "    display(df.limit(num_rows))\n",
    "\n",
    "    print(\"\\n Null Count per Column:\")\n",
    "    nulls = df.select([ count(when(col(c).isNull(),c)).alias(c) for c in df.columns ])\n",
    "    display(nulls)\n",
    "\n",
    "    print(\"\\n Summary Statistics:\")\n",
    "    display(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d38012d-12f3-49d0-8aae-825fdc33b905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "profile_dataframe(df_application_train, \"application_train\")\n",
    "profile_dataframe(df_previous_application, \"previous_application\")\n",
    "profile_dataframe(df_bureau, \"bureau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a835097b-fa75-4643-9c31-2c97b69b7192",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb1adf88-50ec-4529-b27d-e22ac92bdb6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Distinct SK_ID_CURR ID in df_bureau, df_previous_application and df_application_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d18b1b5-b7bd-4ef3-b1bb-06958c67ceff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print ('previous_application dataset unique client ID count :-',df_previous_application.select(col(\"SK_ID_CURR\")).distinct().count())\n",
    "print ('application_train dataset uniqu client ID count :-',df_application_train.select(col(\"SK_ID_CURR\")).distinct().count())\n",
    "print ('bureau dataset unique client ID count :-',df_bureau.select(col(\"SK_ID_CURR\")).distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99991e18-bb37-491f-97ff-780745f5ac96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Distinct CREDIT_ACTIVE and CREDIT_CURRENCY values in bureau table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffd488ba-0cf1-4def-91e6-3dcbef3210c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bureau.select('CREDIT_ACTIVE').distinct().display()\n",
    "df_bureau.select('CREDIT_CURRENCY').distinct().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0dad6e-d58f-4209-9b4c-9efe131c661c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Distribution of data w.r.t to credit_currency. We can later consider only currency 1 since almost all data belongs to this category and drop other categories for consistency in our future calculations and avoid noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd9f71e9-a41a-422a-acc6-d013440e3336",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bureau.select('CREDIT_CURRENCY').groupBy('CREDIT_CURRENCY').count().display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cf51416-0acf-422f-bb1d-81c9378f9921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca30a411-2885-4038-95fc-af8a22295b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Exploration of credit_card_balance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1fa873c-189d-4c1c-96f2-799b425e4a6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Customer Credit Behavior Summary (SK_ID_CURR = 378907):\n",
    "\n",
    "The customer had a credit account (SK_ID_PREV = 2562384) that was paid off around month -20. A new credit cycle began around month -11 under the same account ID, indicating revolving credit behavior. AMT_BALANCE and AMT_TOTAL_RECEIVABLE show how the outstanding principal and total dues (including interest/fees) evolved over time. This suggests the customer reuses the same credit line, typical of credit card or revolving loan products.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e951575c-4f28-425c-9e99-51f66949c7db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_credit_card_balance.filter(col('SK_ID_CURR') == 378907).orderBy(col('MONTHS_BALANCE').desc()).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87461882-7b2c-466b-8652-5b7829bea865",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Customer Credit Behavior Summary (SK_ID_CURR = 260530):\n",
    "\n",
    "This customer had a credit account (SK_ID_PREV = 2332438) that became active around month -11 with a large ATM drawing (₹247,500), followed by partial repayment in month -10. From month -9 onward, the balance dropped to zero. However, SK_DPD and SK_DPD_DEF show high values (up to 189), indicating significant payment delays or defaults prior to loan closure. Despite the final NAME_CONTRACT_STATUS being “Completed,” the historical overdue days suggest prior delinquency or late repayment behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0d5d406-fd28-49fc-bce5-2705aec1b7c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_credit_card_balance.filter(col('SK_ID_CURR') == 260530).orderBy(col('MONTHS_BALANCE').desc()).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "048cdf13-6a17-471f-bc4b-43177a1d7d07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cafe77d-ffe1-4259-9a88-ec0bc197469c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Feature Elimination: Dropping Unnecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feb411e2-79ba-4858-9ee1-06a576ff4a72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_application_train(df):\n",
    "    \"\"\"\n",
    "    Select only the key columns from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing only the selected key columns.\n",
    "    \"\"\"\n",
    "    key_columns = [\n",
    "        \"SK_ID_CURR\",\n",
    "        \"TARGET\",\n",
    "        \"NAME_CONTRACT_TYPE\",\n",
    "        \"CODE_GENDER\",\n",
    "        \"FLAG_OWN_CAR\",\n",
    "        \"FLAG_OWN_REALTY\",\n",
    "        \"CNT_CHILDREN\",\n",
    "        \"AMT_INCOME_TOTAL\",\n",
    "        \"AMT_CREDIT\",\n",
    "        \"AMT_ANNUITY\",\n",
    "        \"AMT_GOODS_PRICE\",\n",
    "        \"NAME_TYPE_SUITE\",\n",
    "        \"NAME_INCOME_TYPE\",\n",
    "        \"NAME_EDUCATION_TYPE\",\n",
    "        \"NAME_FAMILY_STATUS\",\n",
    "        \"NAME_HOUSING_TYPE\",\n",
    "        \"DAYS_BIRTH\",\n",
    "        \"DAYS_EMPLOYED\",\n",
    "        \"FLAG_MOBIL\",\n",
    "        \"FLAG_WORK_PHONE\",\n",
    "        \"FLAG_PHONE\",\n",
    "        \"FLAG_EMAIL\",\n",
    "        \"CNT_FAM_MEMBERS\",\n",
    "        \"EXT_SOURCE_1\",\n",
    "        \"EXT_SOURCE_2\",\n",
    "        \"EXT_SOURCE_3\",\n",
    "        \"DAYS_REGISTRATION\",\n",
    "        \"DAYS_ID_PUBLISH\"\n",
    "    ]\n",
    "    return df.select(*key_columns)\n",
    "\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def extract_features_credit_card_balance(df):\n",
    "    \"\"\"\n",
    "    Select only the key columns from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing only the selected key columns.\n",
    "    \"\"\"\n",
    "\n",
    "    key_columns = [\n",
    "        'SK_ID_CURR',            # Application ID\n",
    "        'SK_ID_PREV',            # Previous credit ID\n",
    "        'MONTHS_BALANCE',        # Time axis\n",
    "        'AMT_BALANCE',           # Current balance\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL',  # Credit limit\n",
    "        'AMT_DRAWINGS_CURRENT',     # Total current drawings\n",
    "        'AMT_PAYMENT_CURRENT',      # Latest payment made\n",
    "        'SK_DPD',                   # Days past due\n",
    "    ]\n",
    "\n",
    "    return df.select(*key_columns)\n",
    "\n",
    "\n",
    "def extract_features_previous_application(df):\n",
    "    \"\"\"\n",
    "    Select only the key columns from the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: DataFrame containing only the selected key columns.\n",
    "    \"\"\"\n",
    "\n",
    "    key_columns = [\n",
    "        \"SK_ID_CURR\",\n",
    "        \"SK_ID_PREV\",\n",
    "        \"NAME_CONTRACT_TYPE\",\n",
    "        \"AMT_APPLICATION\",\n",
    "        \"AMT_CREDIT\",\n",
    "        \"AMT_DOWN_PAYMENT\",\n",
    "        \"AMT_ANNUITY\",\n",
    "        \"NAME_CASH_LOAN_PURPOSE\",\n",
    "        \"NAME_CLIENT_TYPE\",\n",
    "        \"NAME_CONTRACT_STATUS\",\n",
    "        \"DAYS_DECISION\",\n",
    "        \"CNT_PAYMENT\"\n",
    "    ]\n",
    "\n",
    "    return df.select(*key_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18cbe075-e807-4052-85ad-f4e51fd84eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_application_train = extract_features_application_train(df_application_train)\n",
    "# df_credit_card_balance = extract_features_credit_card_balance(df_credit_card_balance)\n",
    "df_previous_application = extract_features_previous_application(df_previous_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1b4a2f3-9783-4450-98fe-44cb7223fada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Transformation (Silver Layer Preparation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36ab0eb0-e94e-4336-b06e-8faf5949cb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Clean and handle null values\n",
    "\n",
    "**Note:-** In bureau dataset since over 99% of records in bureau have CREDIT_CURRENCY = 'currency 1', it's better to filter out the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9f4e5c3-ad7d-46fd-bca0-dc02201bf31b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit\n",
    "from pyspark.sql.functions import median as _median\n",
    "\n",
    "def clean_bureau(df):\n",
    "    # Keep only rows with CREDIT_CURRENCY = 'currency 1'\n",
    "    df = df.filter(col(\"CREDIT_CURRENCY\") == \"currency 1\")\n",
    "\n",
    "    # Drop AMT_ANNUITY due to excessive nulls\n",
    "    df = df.drop(\"AMT_ANNUITY\")\n",
    "    \n",
    "    # Fill other numeric columns with 0 or default\n",
    "    df = df.fillna({\n",
    "        \"DAYS_CREDIT_ENDDATE\": 0,\n",
    "        \"DAYS_ENDDATE_FACT\": 0,\n",
    "        \"AMT_CREDIT_MAX_OVERDUE\": 0,\n",
    "        \"AMT_CREDIT_SUM_DEBT\": 0,\n",
    "        \"AMT_CREDIT_SUM_LIMIT\": 0\n",
    "    })\n",
    "    \n",
    "    # Drop rows with null in AMT_CREDIT_SUM (only 13 rows)\n",
    "    df = df.filter(col(\"AMT_CREDIT_SUM\").isNotNull())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_previous_application(df):\n",
    "    # Fill numeric nulls with 0\n",
    "    df = df.fillna({\n",
    "        \"AMT_DOWN_PAYMENT\": 0,\n",
    "        \"AMT_ANNUITY\": 0,\n",
    "        \"CNT_PAYMENT\": 0\n",
    "    })\n",
    "\n",
    "    # Drop rows with null in AMT_CREDIT (only 1 row)\n",
    "    df = df.filter(col(\"AMT_CREDIT\").isNotNull())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_application_train(df):\n",
    "    # Fill categorical with 'Unknown'\n",
    "    df = df.fillna({\"NAME_TYPE_SUITE\": \"Unknown\"})\n",
    "\n",
    "    # Get medians for imputation\n",
    "    medians = df.selectExpr(\n",
    "        \"percentile_approx(AMT_ANNUITY, 0.5) as median_annuity\",\n",
    "        \"percentile_approx(AMT_GOODS_PRICE, 0.5) as median_goods_price\",\n",
    "        \"percentile_approx(CNT_FAM_MEMBERS, 0.5) as median_fam\",\n",
    "        \"percentile_approx(EXT_SOURCE_1, 0.5) as median_ext1\",\n",
    "        \"percentile_approx(EXT_SOURCE_2, 0.5) as median_ext2\",\n",
    "        \"percentile_approx(EXT_SOURCE_3, 0.5) as median_ext3\"\n",
    "    ).collect()[0]\n",
    "\n",
    "    df = df.fillna({\n",
    "        \"AMT_ANNUITY\": medians[\"median_annuity\"],\n",
    "        \"AMT_GOODS_PRICE\": medians[\"median_goods_price\"],\n",
    "        \"CNT_FAM_MEMBERS\": medians[\"median_fam\"],\n",
    "        \"EXT_SOURCE_1\": medians[\"median_ext1\"],\n",
    "        \"EXT_SOURCE_2\": medians[\"median_ext2\"],\n",
    "        \"EXT_SOURCE_3\": medians[\"median_ext3\"]\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e60bb2-5fc1-4f9e-82e0-9fd69ad2b1fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_application_train = clean_application_train(df_application_train)\n",
    "df_previous_application = clean_previous_application(df_previous_application)\n",
    "df_bureau = clean_bureau(df_bureau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c45e9fb-f0e1-434c-a324-609cd8dc5f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a61b555-56fc-4737-8b75-519da8dffc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Bureau Data Aggregation (**df_bureau_agg**), Previous Application Data Aggregation (**df_prev_agg**) and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad4969e-4a7c-44cb-a357-8d264e3f4be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, avg, sum, max, count, when\n",
    "\n",
    "df_bureau_agg = df_bureau.groupBy(\"SK_ID_CURR\").agg(\n",
    "    count(\"*\").alias(\"bureau_record_count\"),\n",
    "    sum(\"AMT_CREDIT_SUM\").alias(\"total_credit_sum\"),\n",
    "    sum(\"AMT_CREDIT_SUM_DEBT\").alias(\"total_credit_debt\"),\n",
    "    avg(\"AMT_CREDIT_SUM_DEBT\").alias(\"avg_credit_debt\"),\n",
    "    avg(\"DAYS_CREDIT\").alias(\"avg_days_credit\"),\n",
    "    max(\"AMT_CREDIT_MAX_OVERDUE\").alias(\"max_overdue\")\n",
    ").withColumn(\n",
    "    \"credit_utilization_ratio\", \n",
    "    col(\"total_credit_debt\") / col(\"total_credit_sum\")\n",
    ")\n",
    "\n",
    "df_prev_agg = df_previous_application.groupBy(\"SK_ID_CURR\").agg(\n",
    "    count(\"*\").alias(\"previous_app_count\"),\n",
    "    sum(\"AMT_CREDIT\").alias(\"total_prev_credit\"),\n",
    "    sum(\"AMT_DOWN_PAYMENT\").alias(\"total_down_payment\"),\n",
    "    avg(\"AMT_ANNUITY\").alias(\"avg_prev_annuity\"),\n",
    "    avg(\"CNT_PAYMENT\").alias(\"avg_cnt_payment\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1ddc635-dc0a-428f-a87a-df98a5750b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Join Aggregated Data with Application Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d5c0fec-dc93-4ff8-a22b-cdf3443f81ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_applicant_profiles_final = df_application_train.alias(\"app\") \\\n",
    "    .join(df_bureau_agg.alias(\"bur\"), on=\"SK_ID_CURR\", how=\"left\") \\\n",
    "    .join(df_prev_agg.alias(\"prev\"), on=\"SK_ID_CURR\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6292c027-6be8-47a0-8941-0542dcf823a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_applicant_profiles_final.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a87c376-cbca-4ba5-a27b-965d83bc3f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Save to Silver Layer (Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4773e6f-cc16-43a8-84f6-bbe0812c6775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_applicant_profiles_final.write.mode(\"overwrite\").parquet(\"abfss://silver@crdpadlsdev.dfs.core.windows.net/applicant_profiles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20af0dcb-0aa5-4224-b2df-6a0439b96c8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d58c40b-b9ab-4a10-9d8a-2c997f784ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Cleaning and Exploration",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
